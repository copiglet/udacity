{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from data_prep.SlicesDataset import SlicesDataset\n",
    "from utils.utils import log_to_tensorboard\n",
    "from utils.volume_stats import Dice3d, Jaccard3d\n",
    "from networks.RecursiveUNet import UNet\n",
    "from inference.UNetInferenceAgent import UNetInferenceAgent\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import numpy as np\n",
    "from medpy.io import load\n",
    "# from utils.utils import med_reshape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class SlicesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    This class represents an indexable Torch dataset\n",
    "    which could be consumed by the PyTorch DataLoader class\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "        self.slices = []\n",
    "\n",
    "        for i, d in enumerate(data):\n",
    "            for j in range(d[\"image\"].shape[0]):\n",
    "                self.slices.append((i, j))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        This method is called by PyTorch DataLoader class to return a sample with id idx\n",
    "\n",
    "        Arguments: \n",
    "            idx {int} -- id of sample\n",
    "\n",
    "        Returns:\n",
    "            Dictionary of 2 Torch Tensors of dimensions [1, W, H]\n",
    "        \"\"\"\n",
    "        slc = self.slices[idx]\n",
    "        sample = dict()\n",
    "        sample[\"id\"] = idx\n",
    "\n",
    "        # You could implement caching strategy here if dataset is too large to fit\n",
    "        # in memory entirely\n",
    "        # Also this would be the place to call transforms if data augmentation is used\n",
    "        \n",
    "        # TASK: Create two new keys in the \"sample\" dictionary, named \"image\" and \"seg\"\n",
    "        # The values are 3D Torch Tensors with image and label data respectively. \n",
    "        # First dimension is size 1, and last two hold the voxel data from the respective\n",
    "        # slices. Write code that stores the 2D slice data in the last 2 dimensions of the 3D Tensors. \n",
    "        # Your tensor needs to be of shape [1, patch_size, patch_size]\n",
    "        # Don't forget that you need to put a Torch Tensor into your dictionary element's value\n",
    "        # Hint: your 3D data sits in self.data variable, the id of the 3D volume from data array\n",
    "        # and the slice number are in the slc variable. \n",
    "        # Hint2: You can use None notation like so: arr[None, :] to add size-1 \n",
    "        # dimension to a Numpy array\n",
    "        # <YOUR CODE GOES HERE>\n",
    "        sample[\"image\"] = []\n",
    "        sample[\"seg\"] = []\n",
    "        \n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        This method is called by PyTorch DataLoader class to return number of samples in the dataset\n",
    "\n",
    "        Returns:\n",
    "            int\n",
    "        \"\"\"\n",
    "        return len(self.slices)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_loader = DataLoader(SlicesDataset(dataset[split[\"train\"]]),"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "root_dir = \"/home/phenomx/dante/udacity/Applying_AI_to_3D_Medical_Imaging_Data/test_sections/nd320-c3-3d-imaging-starter/data/TrainingSet\"\n",
    "image_dir = os.path.join(root_dir, 'images')\n",
    "label_dir = os.path.join(root_dir, 'labels')\n",
    "\n",
    "images = [f for f in listdir(image_dir) if (isfile(join(image_dir, f)) and f[0] != \".\")]\n",
    "images[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def med_reshape(image, new_shape):\n",
    "    \"\"\"\n",
    "    This function reshapes 3D data to new dimension padding with zeros\n",
    "    and leaving the content in the top-left corner\n",
    "\n",
    "    Arguments:\n",
    "        image {array} -- 3D array of pixel data\n",
    "        new_shape {3-tuple} -- expected output shape\n",
    "\n",
    "    Returns:\n",
    "        3D array of desired shape, padded with zeroes\n",
    "    \"\"\"\n",
    "\n",
    "    reshaped_image = np.zeros(new_shape)\n",
    "\n",
    "    # TASK: write your original image into the reshaped image\n",
    "    # <CODE GOES HERE>\n",
    "    print(reshaped_image.shape)\n",
    "    print(image.shape)\n",
    "    # return reshaped_image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "f = images[0]\n",
    "image, _ = load(os.path.join(image_dir, f))\n",
    "label, _ = load(os.path.join(label_dir, f))\n",
    "\n",
    "# TASK: normalize all images (but not labels) so that values are in [0..1] range\n",
    "# <YOUR CODE GOES HERE>\n",
    "slice_num = len(image.swapaxes(0,1))\n",
    "for slice_ix in range(slice_num):\n",
    "    image[:,slice_ix,:] = image[:,slice_ix,:].astype(np.single)/np.max(image[:,slice_ix,:])\n",
    "\n",
    "# image = med_reshape(image, new_shape=(image.shape[0], image.shape[2], image.shape[1]))\n",
    "# label = med_reshape(label, new_shape=(label.shape[0], label.shape[2], label.shape[1])).astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "med_reshape(image, new_shape=(image.shape[0], image.shape[2], image.shape[1]))\n",
    "# label = med_reshape(label, new_shape=(label.shape[0], label.shape[2], label.shape[1])).astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from experiments.UNetExperiment import UNetExperiment\n",
    "from data_prep.HippocampusDatasetLoader import LoadHippocampusData\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from data_prep.SlicesDataset import SlicesDataset\n",
    "from utils.utils import log_to_tensorboard\n",
    "from utils.volume_stats import Dice3d, Jaccard3d\n",
    "from networks.RecursiveUNet import UNet\n",
    "from inference.UNetInferenceAgent import UNetInferenceAgent\n",
    "from medpy.io import load"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "a, _ = load('/home/phenomx/dante/udacity/Applying_AI_to_3D_Medical_Imaging_Data/test_sections/nd320-c3-3d-imaging-starter/data/TrainingSet/images/hippocampus_010.nii.gz')\n",
    "a.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(512, 512, 241)"
      ]
     },
     "metadata": {},
     "execution_count": 174
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "root_dir = \"/home/phenomx/dante/udacity/Applying_AI_to_3D_Medical_Imaging_Data/test_sections/nd320-c3-3d-imaging-starter/data/TrainingSet\"\n",
    "batch_size = 8\n",
    "patch_size = 64"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "data = LoadHippocampusData(root_dir, y_shape = patch_size, z_shape = patch_size)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processed 262 files, total 10222 slices\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "keys = range(len(data))\n",
    "\n",
    "split = dict()\n",
    "\n",
    "\n",
    "split[\"train\"]=keys[:int(len(keys)*0.8)]\n",
    "split[\"test\"]=keys[int(len(keys)*0.8):int(len(keys)*0.9)]\n",
    "split[\"val\"]=keys[int(len(keys)*0.9):]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "train_loader = DataLoader(SlicesDataset(data[split[\"train\"]]),\n",
    "                batch_size=batch_size, shuffle=True, num_workers=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "# for i, batch in enumerate(train_loader):\n",
    "#     print(i)\n",
    "#     print(batch)\n",
    "#     print(batch['id'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "data = data[split[\"train\"]]\n",
    "\n",
    "slices = []\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "    for j in range(d[\"image\"].shape[0]):\n",
    "        slices.append((i, j))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "data[0][\"image\"].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(34, 34, 50)"
      ]
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "np.unique(data[0][\"image\"][0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "idx = 0\n",
    "slc = slices[idx]\n",
    "sample = dict()\n",
    "sample[\"id\"] = idx"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "slc"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "metadata": {},
     "execution_count": 149
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "a = np.unique(data[0]['image'][0,:,:][None,:,:])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "a"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('dante': conda)"
  },
  "interpreter": {
   "hash": "337f6ecfd5d165a8e41b56d2485d605029982f9d284002502318d083434fd6aa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}